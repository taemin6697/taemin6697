### Hello ğŸ‘‹, I'm Tae-min Kim, whose dream is to become an AI researcher.

---

<h3 align="center">ğŸ›  TECH STACK ğŸ› </h3>
<p align="center">
    <img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=Python&logoColor=white"/>
    <img src="https://img.shields.io/badge/c-%2300599C.svg?style=flate&logo=c&logoColor=white"/>
    <br/>
    <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white"/>
    <img src="https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=flat&logo=TensorFlow&logoColor=white"/>
    <br/>
    <img src="https://img.shields.io/badge/-RaspberryPi-C51A4A?style=falt&logo=Raspberry-Pi"/>
    <img src="https://img.shields.io/badge/-Arduino-00979D?style=flat&logo=Arduino&logoColor=white"/>
    
---

### Experiences
> * __Alethio ML Researcher Intern, [Alethio](https://alethio.io/)__ / 2023.08 ~
> * __LG Aimers 3th, [LG Aimers](https://www.lgaimers.ai/)__ / 2023.07 ~ 2023.09
> * __NLP AI Developer 5th, [BoostCamp AI Tech](https://boostcamp.connect.or.kr/)__ / 2023.03 ~ 2023.08
> * __Hansung University Undergraduate researcher : [Visual Intelligence Lab](https://sites.google.com/view/hs-vilab).__ / 2023.03 ~ 2023.04
> * __Hansung University Undergraduate researcher : [Marusys edu Co., Ltd.](http://marusysedu.kr/)__ / 2022.06 ~ 2023.03
---
    
### Competitions & Project
> * __Boostcamp AI Tech - LawBot(Legal-GPT) Project Serving, [Final Project](https://github.com/taemin6697/level3_nlp_finalproject-nlp-08/tree/main)__ / 2023.07. ~ 2023.08.
> * __Boostcamp AI Tech - Open-Domain Question Answering, [ODQA](https://github.com/taemin6697/level2_nlp_mrc-nlp-08)__ / 2023.06.07 ~ 2023.06.22
> * __Boostcamp AI Tech - Topic Classification, [TC](https://velog.io/@tm011899/%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%94%84-5%EA%B8%B0-1213%EC%A3%BC%EC%B0%A8-%EC%A3%BC%EA%B0%84-%ED%9A%8C%EA%B3%A0KlUE-TC-%EB%8C%80%ED%9A%8C)__ / 2023.05.24 ~ 2023.06.01
> * __Boostcamp AI Tech - Relation Extraction, [RE](https://github.com/taemin6697/level2_klue-nlp-08)__ / 2023.05.03 ~ 2023.05.18
> * __2023ë…„ K-ë””ì§€í„¸ íŠ¸ë ˆì´ë‹ í•´ì»¤í†¤ ì˜ˆì„  ì§„ì¶œ__ / 2023.05.17
> * __Boostcamp AI Tech - Semantic Text Similarity, [STS](https://github.com/taemin6697/Level1_Semantictextsimilarity-Nlp-11)__ / 2023.04.12 ~ 2023.04.20
> * __Visual Intelligence Lab, Food Object Detection Project__ / 2023.03. ~ 2023.04.
> * __2023 êµì›ê·¸ë£¹ AI ì±Œë¦°ì§€ ë³¸ì„  ì§„ì¶œ, [Dacon](https://dacon.io/competitions/open/236057/overview/description)__ / 2023.01.30 ~ 2023.02.13
> * __TV ì† ë™ì‘ ì œì–´ ë¹„ë””ì˜¤ ì¸ì‹ AI ê²½ì§„ëŒ€íšŒ, [Dacon](https://dacon.io/competitions/official/236050/overview/description)__ / 2023.01.02 ~ 2023.02.06
> * __2022 êµ­ë°© AI ê²½ì§„ëŒ€íšŒ ë³¸ì„  ì§„ì¶œ, [AI Connect](https://aiconnect.kr/competition/detail/213)__ / 2022-09-30 ~ 2022-12-01
> * __Marusys edu Co., Ltd. ìœ ì•„ìš© AI TeachableMachine ê°œë°œ, [Marusys edu Co., Ltd.](http://marusysedu.kr/)__ / 2022-06. ~ 2023-03.
----

### Paper Review
> * __Visual Instruction Tuning / [LLaVA](https://velog.io/@tm011899/LLaVA-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0Visual-Instruction-Tuning)__
> * __VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text / [VATT](https://velog.io/@tm011899/VATT-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0VATT-Transformers-for-Multimodal-Self-Supervised-Learning-from-Raw-Video-Audio-and-Text-4f8n4dkl)__
> * __One Embedding Space To Bind Them ALL / [ImageBind](https://velog.io/@tm011899/ImageBind-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0One-Embedding-Space-To-Bind-Them-ALL)__
> * __HyperNetworks for Fast Personalization of Text-to-Image Models / [HyperDreambooth](https://velog.io/@tm011899/HyperDreambooth-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0HyperDreamBooth-HyperNetworks-for-FastPersonalization-of-Text-to-Image-Models)__
> * __A Successor to Transformer for Large Language Models / [RetNet](https://velog.io/@tm011899/RetNet-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0A-Successor-to-Transformer-for-Large-Language-Models)__
> * __Language Models are Unsupervised Multitask Learners / [GPT-2](
https://velog.io/@tm011899/GPT-2-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0Language-Models-are-Unsupervised-Multitask-Learners%EC%9E%91%EC%84%B1-%EC%98%88%EC%A0%95
)__
> * __Learning Transferable Visual Models From Natural Language Supervision / [CLIP](https://velog.io/@tm011899/CLIP-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0)__
> * __Improving Language Understanding by Generative Pre-Training / [GPT-1](https://velog.io/@tm011899/GPT-%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8)__
> * __Pre-training of Deep Bidirectional Transformers for Language Understanding / [BERT](https://velog.io/@tm011899/BERT-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0%EC%93%B0%EB%8A%94%EC%A4%91)__
> * __Attention is all you need / [Transformer](https://velog.io/@tm011899/%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%94%84-5%EA%B8%B0-5%EC%A3%BC%EC%B0%A8-Transformer)__
> * __Effective Approaches to Attention-based Neural Machine Translation / [Seq2Seq with Attention](https://github.com/taemin6697/Paper_Review/blob/master/Seq2Seq_with_attention.pdf)__
> * __Sequence to Sequence Learning with Neural Networks / [Seq2Seq](https://github.com/taemin6697/Paper_Review/blob/master/Seq2Seq.pdf)__
> * __TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models / [TrOCR](https://github.com/taemin6697/Paper_Review/blob/master/Trocr.pdf)__
> * __SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers / [Segformer](https://github.com/taemin6697/Paper_Review/blob/master/SegFormer.pdf)__
> * __An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale / [Vision Transformer](https://www.youtube.com/watch?v=sOY0H_EeH3Q&ab_channel=%ED%83%9C%EB%AF%BC%EA%B9%80)__
> * __Involution: Inverting the Inherence of Convolution for Visual Recognition / [Involution](https://github.com/taemin6697/Paper_Review/blob/master/involution.pdf)__
> * __Micro-Batch Training with Batch-Channel Normalization and Weight Standardization / [Weight Standardization](https://github.com/taemin6697/Paper_Review/blob/master/Weight%20Standardization-re.pdf)__
> * __Big Transfer (BiT): General Visual Representation Learning / [BiT](https://github.com/taemin6697/Paper_Review/blob/master/BiT(AI%20study).pdf)__
> #### ì¼ë¶€ ë¦¬ë·°ëŠ” [Youtube](https://www.youtube.com/@user-dt2tf9mm8y/videos), [Velog](https://velog.io/@tm011899)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
----

### Uploaded Model <img src="https://huggingface.co/landing/assets/transformers-docs/huggingface_logo.svg" alt="huggingface" width="20" height="20"/>
> * __kfkas/Legal-Llama-2-ko-7b-Chatâš–ï¸ğŸ¦™ / [Huggingface](https://huggingface.co/kfkas/Legal-Llama-2-ko-7b-Chat)__
> * __YoonSeul/LawBot-level-3-KuLLM-5.8B-tae-2epochâš–ï¸ / [Huggingface](https://huggingface.co/YoonSeul/LawBot-level-3-KuLLM-5.8B-tae-2epoch)__
> * __kfkas/Llama-2-ko-7b-ChatğŸ¦™ / [Huggingface](https://huggingface.co/kfkas/Llama-2-ko-7b-Chat)__
> * __kfkas/legal-question-filter-koelectra / [Huggingface](https://huggingface.co/kfkas/legal-question-filter-koelectra)__
> * __kfkas/t5-large-korean-P2G / [Huggingface](https://huggingface.co/kfkas/t5-large-korean-P2G)__
> * __kfkas/t5-large-korean-news-title-klue-ynat / [Huggingface](https://huggingface.co/kfkas/t5-large-korean-news-title-klue-ynat)__
> * __kfkas/RoBERTa-large-Detection-G2P / [Huggingface](https://huggingface.co/kfkas/RoBERTa-large-Detection-P2G)__
> #### ğŸ‰kfkas/Llama-2-ko-7b-ChatğŸ¦™ ëª¨ë¸ì´ 13k ë‹¤ìš´ë¡œë“œë¥¼ ëŒíŒŒí•˜ì˜€ìŠµë‹ˆë‹¤.ğŸ‰
----



ï»¿ï»¿[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=taemin6697&langs_count=10&layout=compact&theme=white)](https://github.com/taemin6697/taemin6697)ï»¿
ï»¿
---

<b> Baekjoon Tier </b>

[![Solved.ac Profile](http://mazassumnida.wtf/api/v2/generate_badge?boj=ktmkjj88)](https://solved.ac/ktmkjj88/)
